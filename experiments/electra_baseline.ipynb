{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets.Dataset import *\n",
    "from models.electra_baseline import *\n",
    "from train.train import *\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/New Augmented_Dataset.csv')\n",
    "category_mapping = {category: idx for idx, category in enumerate(df['prompt'].unique())}\n",
    "df['prompt_id'] = df['prompt'].map(category_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~np.isin(df['prompt_id'], np.arange(100))]\n",
    "test_df =  df[np.isin(df['prompt_id'],  np.arange(100))]\n",
    "dev_df, test_df = train_test_split(test_df, test_size=0.5, shuffle=True, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "dev_df = dev_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, tokenizer)\n",
    "valid_dataset = CustomDataset(dev_df, tokenizer)\n",
    "test_dataset = CustomDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_len = 512\n",
    "epochs = 20\n",
    "learning_rate = 2e-5\n",
    "experiment_name = \"electra_baseline\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          num_workers=4, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                          num_workers=4, shuffle=False, pin_memory=True)\n",
    "set_seed(42)\n",
    "model = ELECTRA()\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=int(total_steps * 0.1))\n",
    "history = train_model(model, criterion, optimizer, scheduler, train_loader, valid_loader, device, experiment_name, epochs=20)\n",
    "results = pd.DataFrame(history)\n",
    "results.to_csv('checkpoints/results_{}.csv'.format(experiment_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ELECTRA()\n",
    "best_model.load_state_dict(torch.load('/checkpoints/electra-w-topic-regression-baseline/best_electra_model1.pth'))\n",
    "best_model = best_model.to(device)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, \n",
    "                          num_workers=4, shuffle=False, pin_memory=False)\n",
    "criterion = nn.MSELoss()\n",
    "maes, qwks, loss = evaluate_model(best_model, test_loader, criterion, device)\n",
    "np.mean(maes), np.mean(qwks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
